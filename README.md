# Pix2Pix 

pre processing 
[![](https://mermaid.ink/img/pako:eNqVVVFr20AM_ivmnhLqldHRMQJ5GJTCXkYhfTQc2llOjp7vjE7ulpX898lO4iRnp3Q2GHH6JH2WPtlvyoQS1UIZBzE-WFgT1IXv7uxw9Z7se7uu0TOwDT57O3m760Zr6y1rPYvoqvnJuTuZab4nsPRoHcY02afQctOyrsSZeEpLaDjQNjmP8Ir6ivOSW54NsDy7DMuzs8LLQjVCMN6a-FqoeZIS_zCBYQ2kwZea7SF3F-mhxhS_xn1W3edMm9RDfpNl1By0FJwEUOv_o7sPwLBqnGVGGjW4FGcUSg3wJnExxslzYTUJJ7BeUyeKSc84ZDSOMy55dooS-0glz47Vj4C-4PLz7bf7tEvaOJSpDEOdDVaKjF13JjtdUah1G5GEqehhZly8bPpIyoRPFAzG-PjjebWyfu3wmqqFz8Q0NG-bVOx98TE-beAAG_Tb20PW9O1KGxm86bUm9os2stWEh2yGHOvwK_aWHyzWhNXhTKyRNrEOskp3ZePAH1MBEWzHSChlFTiebUw_2hHNVuZjQHaie5MzsQiLDXiPLi6_pEE-UA3O_p0I2khhpOXP4HHMKU6GMFC3uHEDDS5nd_df80we8zS82Y_-THMfX9_3lfRMthkr6Sa7NsIPDi9bZJULwGnaZIr7-QnYl705-u7snypXNUrbbSk_kZ5qoXiDNRZqIabEvhSq8DvBQcthtfVGLSpwEXPVNtJpPPx0Dqe7fyGB9vk?type=png)](https://mermaid-js.github.io/mermaid-live-editor/edit#pako:eNqVVVFr20AM_ivmnhLqldHRMQJ5GJTCXkYhfTQc2llOjp7vjE7ulpX898lO4iRnp3Q2GHH6JH2WPtlvyoQS1UIZBzE-WFgT1IXv7uxw9Z7se7uu0TOwDT57O3m760Zr6y1rPYvoqvnJuTuZab4nsPRoHcY02afQctOyrsSZeEpLaDjQNjmP8Ir6ivOSW54NsDy7DMuzs8LLQjVCMN6a-FqoeZIS_zCBYQ2kwZea7SF3F-mhxhS_xn1W3edMm9RDfpNl1By0FJwEUOv_o7sPwLBqnGVGGjW4FGcUSg3wJnExxslzYTUJJ7BeUyeKSc84ZDSOMy55dooS-0glz47Vj4C-4PLz7bf7tEvaOJSpDEOdDVaKjF13JjtdUah1G5GEqehhZly8bPpIyoRPFAzG-PjjebWyfu3wmqqFz8Q0NG-bVOx98TE-beAAG_Tb20PW9O1KGxm86bUm9os2stWEh2yGHOvwK_aWHyzWhNXhTKyRNrEOskp3ZePAH1MBEWzHSChlFTiebUw_2hHNVuZjQHaie5MzsQiLDXiPLi6_pEE-UA3O_p0I2khhpOXP4HHMKU6GMFC3uHEDDS5nd_df80we8zS82Y_-THMfX9_3lfRMthkr6Sa7NsIPDi9bZJULwGnaZIr7-QnYl705-u7snypXNUrbbSk_kZ5qoXiDNRZqIabEvhSq8DvBQcthtfVGLSpwEXPVNtJpPPx0Dqe7fyGB9vk)


main 
[![](https://mermaid.ink/img/pako:eNq9WG1v2zYQ_iuCPgxu5wDtsE8GXMCbnTVAkhmJg22AAYKRKJuLRLIklcTr8t93pChZIqnEHYYZCEwf7453D--N-ZpmPCfpLM1KrNSS4p3E1ZYl8MmpJJmmnCWXNw3F8iQLIZKvDcF8vkeIMqoRmihSFu96G7JmfdrLljULhiuiBM5IssQa93U1BxjqJcc5kf098zkTmErl0XJgV0Sjxl4uD8P9oX3TJGCfJpl6RALr_TtPsgQjnBSt8I6ggpbEZ0KGC9n9gNdqRZowxWVMeSOGjFetLMvJcyjxclzG0AJ_Aqjusc72SNG_iL9RFwWRsR0DjXWHyLcxdIzTpKdv_uOHD0DoTp5_9L3OJMGaIHcJfsi8jEbKFWaAlFRhtFxB_JZuOwAh46ygO4-4-n29urm4Wl1vbtHy4sbb_fwH7K4XN4ur1WZ1c4vWi83n19CI3mtzrkOr-RGNsB0EIn7EtMT3EC3ZnmQPglOmVVS1kLwSGhVc9lijnEavvaQuyvs3pw-CjFwMZjm6r2mZo8rgqibD2_HB30gMULDdCP5-3LzHcqfg6_3Dk1kFNtRSEqYReRZE0sosNXwpjSsRddMZ3eMf-uvza2Nu45mzqKG0BQB-w2m9n0PNcJUd7JZhfs1ZgCSXwKVAMVimHT6RQPehXD3issam3v43YNoQIAWuSwC0023NbuNy6ExMQUEZLpHCj-QbBC1770hJFBihnLCncppUiiDDTAIXnA4yvLHhDXm2TBOr2dZVFbWufz1HI0cqUazgnkNhH7sia02TeeSZKnC6C8ggdrk4NJyaQ0qXUEsnitcyI02o5cZPWJ1m1J0i8oKJWo9Z9qUm8oAOAArjk6aQRIuR7fiTk2qyoM8_wF9Ykm1ViFTjnKoMsgkCAABBXEByQ5OQfs3ubtTb2BGGdphB41H-DKDqqsLg35OkOlAIckSaI8foJ5iChCQFfY44FDPHWFp-jO0MIIhIaa4hO0JBP_k722fJL-0SYqavfZYs-z8hMwYgDVPHehcvl0oT0U0nEGFNckEiQtUhGtTCvi9ZUD0osLlyiWsWRkCFtdUmbiHJl9fr5MCpIMRspfBoBk3E7_-EPPTMzPkTU9BcSjKBcQ1AMdZBHEwTLER5QHaSYVxW842sg0Lf65PRbjMMd2NF24RN2EDrKhGvNSDqKO5OSe7Ip2V-d_0nYfHr3WZ9t0E_f15cX68ub73dy8XVT8vF_wRfLV6TzSUXAMP8HJfqm5E_ZraPuo-xzaRu3YT0ScXvTtMyMo1emNxYS54RpfgbLdy3GiIih44LTaN7O5h22T4joGdF543WJdf0nLcWnEHGuldF66VHbBjNacbH9hHjOjTomm9Tm8rb9LSwXC_Pf7N1JsCgs_eeP9t582lP1QO8IETJ9eQ4DbiKEB9NnAqQ1Nw8Wf-NsMgLyELBpZ4EU0Q3d_bnk8jw0mA-EjHN0ryXz84-BbPyLGnGV5V8Z54IWvJSDSXCkTAu00j5-o2G9nE4S2pFnPZQa4yz4e09xQ2TF90zGFIEYblK-Bs2OB2nmeExN-yDZ57h7I9hfb0xE8Z44zbEuMd0__1paNkMEmkPbU2rpIAha_yYNwXHvWnHq9PgDybDodhrQIwfFOc_5vypEm8GVFzsJJ_aLIowHyMgCKtR7h7CbawOJpEgBh3XsT-PcbwKwql4t0ZuWTpNKyIrTPN0ltriC6V7TyqyTWewzLF82KZb9gJ8uNb89sCydFaYNjtNawEvEuL-DeioL_8Ax7dT8g?type=png)](https://mermaid-js.github.io/mermaid-live-editor/edit#pako:eNq9WG1v2zYQ_iuCPgxu5wDtsE8GXMCbnTVAkhmJg22AAYKRKJuLRLIklcTr8t93pChZIqnEHYYZCEwf7453D--N-ZpmPCfpLM1KrNSS4p3E1ZYl8MmpJJmmnCWXNw3F8iQLIZKvDcF8vkeIMqoRmihSFu96G7JmfdrLljULhiuiBM5IssQa93U1BxjqJcc5kf098zkTmErl0XJgV0Sjxl4uD8P9oX3TJGCfJpl6RALr_TtPsgQjnBSt8I6ggpbEZ0KGC9n9gNdqRZowxWVMeSOGjFetLMvJcyjxclzG0AJ_Aqjusc72SNG_iL9RFwWRsR0DjXWHyLcxdIzTpKdv_uOHD0DoTp5_9L3OJMGaIHcJfsi8jEbKFWaAlFRhtFxB_JZuOwAh46ygO4-4-n29urm4Wl1vbtHy4sbb_fwH7K4XN4ur1WZ1c4vWi83n19CI3mtzrkOr-RGNsB0EIn7EtMT3EC3ZnmQPglOmVVS1kLwSGhVc9lijnEavvaQuyvs3pw-CjFwMZjm6r2mZo8rgqibD2_HB30gMULDdCP5-3LzHcqfg6_3Dk1kFNtRSEqYReRZE0sosNXwpjSsRddMZ3eMf-uvza2Nu45mzqKG0BQB-w2m9n0PNcJUd7JZhfs1ZgCSXwKVAMVimHT6RQPehXD3issam3v43YNoQIAWuSwC0023NbuNy6ExMQUEZLpHCj-QbBC1770hJFBihnLCncppUiiDDTAIXnA4yvLHhDXm2TBOr2dZVFbWufz1HI0cqUazgnkNhH7sia02TeeSZKnC6C8ggdrk4NJyaQ0qXUEsnitcyI02o5cZPWJ1m1J0i8oKJWo9Z9qUm8oAOAArjk6aQRIuR7fiTk2qyoM8_wF9Ykm1ViFTjnKoMsgkCAABBXEByQ5OQfs3ubtTb2BGGdphB41H-DKDqqsLg35OkOlAIckSaI8foJ5iChCQFfY44FDPHWFp-jO0MIIhIaa4hO0JBP_k722fJL-0SYqavfZYs-z8hMwYgDVPHehcvl0oT0U0nEGFNckEiQtUhGtTCvi9ZUD0osLlyiWsWRkCFtdUmbiHJl9fr5MCpIMRspfBoBk3E7_-EPPTMzPkTU9BcSjKBcQ1AMdZBHEwTLER5QHaSYVxW842sg0Lf65PRbjMMd2NF24RN2EDrKhGvNSDqKO5OSe7Ip2V-d_0nYfHr3WZ9t0E_f15cX68ub73dy8XVT8vF_wRfLV6TzSUXAMP8HJfqm5E_ZraPuo-xzaRu3YT0ScXvTtMyMo1emNxYS54RpfgbLdy3GiIih44LTaN7O5h22T4joGdF543WJdf0nLcWnEHGuldF66VHbBjNacbH9hHjOjTomm9Tm8rb9LSwXC_Pf7N1JsCgs_eeP9t582lP1QO8IETJ9eQ4DbiKEB9NnAqQ1Nw8Wf-NsMgLyELBpZ4EU0Q3d_bnk8jw0mA-EjHN0ryXz84-BbPyLGnGV5V8Z54IWvJSDSXCkTAu00j5-o2G9nE4S2pFnPZQa4yz4e09xQ2TF90zGFIEYblK-Bs2OB2nmeExN-yDZ57h7I9hfb0xE8Z44zbEuMd0__1paNkMEmkPbU2rpIAha_yYNwXHvWnHq9PgDybDodhrQIwfFOc_5vypEm8GVFzsJJ_aLIowHyMgCKtR7h7CbawOJpEgBh3XsT-PcbwKwql4t0ZuWTpNKyIrTPN0ltriC6V7TyqyTWewzLF82KZb9gJ8uNb89sCydFaYNjtNawEvEuL-DeioL_8Ax7dT8g)


post processing 
[![](https://mermaid.ink/img/pako:eNp9kcFqwzAMhl_F6LQx7wVyHoXdCtnRYDRbbcVsOdjOoSt59zppaEsY0-lH-n7J_L6AS56gAxewlA_GY8ZoRK21dNU-lbrPyVEpu8-vvmc5BlKXBzbXexrrMFbrOW8GHivaeh5o02f5k3-zloWrtS-FwkGrO6bV44RW962vG7snSTli4F-yM7SumeU_LpfiNwtZd0IRCuXJtUWHWxQL8TSbbtIIaIjUXsC-5bqkZKCeKJKBrkmP-ceAkalxONbUn8VBd8BQSMM4tIu0_sPana6igoCi?type=png)](https://mermaid-js.github.io/mermaid-live-editor/edit#pako:eNp9kcFqwzAMhl_F6LQx7wVyHoXdCtnRYDRbbcVsOdjOoSt59zppaEsY0-lH-n7J_L6AS56gAxewlA_GY8ZoRK21dNU-lbrPyVEpu8-vvmc5BlKXBzbXexrrMFbrOW8GHivaeh5o02f5k3-zloWrtS-FwkGrO6bV44RW962vG7snSTli4F-yM7SumeU_LpfiNwtZd0IRCuXJtUWHWxQL8TSbbtIIaIjUXsC-5bqkZKCeKJKBrkmP-ceAkalxONbUn8VBd8BQSMM4tIu0_sPana6igoCi)



- This code is based on the [TensorFlow](https://www.tensorflow.org/tutorials/generative/pix2pix) implementation of Pix2Pix. 
- The original Pix2Pix paper can be found at [Image-to-image translation with conditional adversarial networks](https://arxiv.org/abs/1611.07004).

  > Isola, P., Zhu, J. Y., Zhou, T., & Efros, A. A. (2017). Image-to-image translation with conditional adversarial networks. In Proceedings of the IEEE conference on computer vision and pattern recognition (pp. 1125-1134).

# Class Diagrams
## Preprocessing 
[![](https://mermaid.ink/img/pako:eNqVVVFr20AM_ivmnhLqldHRMQJ5GJTCXkYhfTQc2llOjp7vjE7ulpX898lO4iRnp3Q2GHH6JH2WPtlvyoQS1UIZBzE-WFgT1IXv7uxw9Z7se7uu0TOwDT57O3m760Zr6y1rPYvoqvnJuTuZab4nsPRoHcY02afQctOyrsSZeEpLaDjQNjmP8Ir6ivOSW54NsDy7DMuzs8LLQjVCMN6a-FqoeZIS_zCBYQ2kwZea7SF3F-mhxhS_xn1W3edMm9RDfpNl1By0FJwEUOv_o7sPwLBqnGVGGjW4FGcUSg3wJnExxslzYTUJJ7BeUyeKSc84ZDSOMy55dooS-0glz47Vj4C-4PLz7bf7tEvaOJSpDEOdDVaKjF13JjtdUah1G5GEqehhZly8bPpIyoRPFAzG-PjjebWyfu3wmqqFz8Q0NG-bVOx98TE-beAAG_Tb20PW9O1KGxm86bUm9os2stWEh2yGHOvwK_aWHyzWhNXhTKyRNrEOskp3ZePAH1MBEWzHSChlFTiebUw_2hHNVuZjQHaie5MzsQiLDXiPLi6_pEE-UA3O_p0I2khhpOXP4HHMKU6GMFC3uHEDDS5nd_df80we8zS82Y_-THMfX9_3lfRMthkr6Sa7NsIPDi9bZJULwGnaZIr7-QnYl705-u7snypXNUrbbSk_kZ5qoXiDNRZqIabEvhSq8DvBQcthtfVGLSpwEXPVNtJpPPx0Dqe7fyGB9vk?type=png)](https://mermaid-js.github.io/mermaid-live-editor/edit#pako:eNqVVVFr20AM_ivmnhLqldHRMQJ5GJTCXkYhfTQc2llOjp7vjE7ulpX898lO4iRnp3Q2GHH6JH2WPtlvyoQS1UIZBzE-WFgT1IXv7uxw9Z7se7uu0TOwDT57O3m760Zr6y1rPYvoqvnJuTuZab4nsPRoHcY02afQctOyrsSZeEpLaDjQNjmP8Ir6ivOSW54NsDy7DMuzs8LLQjVCMN6a-FqoeZIS_zCBYQ2kwZea7SF3F-mhxhS_xn1W3edMm9RDfpNl1By0FJwEUOv_o7sPwLBqnGVGGjW4FGcUSg3wJnExxslzYTUJJ7BeUyeKSc84ZDSOMy55dooS-0glz47Vj4C-4PLz7bf7tEvaOJSpDEOdDVaKjF13JjtdUah1G5GEqehhZly8bPpIyoRPFAzG-PjjebWyfu3wmqqFz8Q0NG-bVOx98TE-beAAG_Tb20PW9O1KGxm86bUm9os2stWEh2yGHOvwK_aWHyzWhNXhTKyRNrEOskp3ZePAH1MBEWzHSChlFTiebUw_2hHNVuZjQHaie5MzsQiLDXiPLi6_pEE-UA3O_p0I2khhpOXP4HHMKU6GMFC3uHEDDS5nd_df80we8zS82Y_-THMfX9_3lfRMthkr6Sa7NsIPDi9bZJULwGnaZIr7-QnYl705-u7snypXNUrbbSk_kZ5qoXiDNRZqIabEvhSq8DvBQcthtfVGLSpwEXPVNtJpPPx0Dqe7fyGB9vk)

## Main Application 
[![](https://mermaid.ink/img/pako:eNq9WG1v2zYQ_iuCPgxu5wDtsE8GXMCbnTVAkhmJg22AAYKRKJuLRLIklcTr8t93pChZIqnEHYYZCEwf7453D--N-ZpmPCfpLM1KrNSS4p3E1ZYl8MmpJJmmnCWXNw3F8iQLIZKvDcF8vkeIMqoRmihSFu96G7JmfdrLljULhiuiBM5IssQa93U1BxjqJcc5kf098zkTmErl0XJgV0Sjxl4uD8P9oX3TJGCfJpl6RALr_TtPsgQjnBSt8I6ggpbEZ0KGC9n9gNdqRZowxWVMeSOGjFetLMvJcyjxclzG0AJ_Aqjusc72SNG_iL9RFwWRsR0DjXWHyLcxdIzTpKdv_uOHD0DoTp5_9L3OJMGaIHcJfsi8jEbKFWaAlFRhtFxB_JZuOwAh46ygO4-4-n29urm4Wl1vbtHy4sbb_fwH7K4XN4ur1WZ1c4vWi83n19CI3mtzrkOr-RGNsB0EIn7EtMT3EC3ZnmQPglOmVVS1kLwSGhVc9lijnEavvaQuyvs3pw-CjFwMZjm6r2mZo8rgqibD2_HB30gMULDdCP5-3LzHcqfg6_3Dk1kFNtRSEqYReRZE0sosNXwpjSsRddMZ3eMf-uvza2Nu45mzqKG0BQB-w2m9n0PNcJUd7JZhfs1ZgCSXwKVAMVimHT6RQPehXD3issam3v43YNoQIAWuSwC0023NbuNy6ExMQUEZLpHCj-QbBC1770hJFBihnLCncppUiiDDTAIXnA4yvLHhDXm2TBOr2dZVFbWufz1HI0cqUazgnkNhH7sia02TeeSZKnC6C8ggdrk4NJyaQ0qXUEsnitcyI02o5cZPWJ1m1J0i8oKJWo9Z9qUm8oAOAArjk6aQRIuR7fiTk2qyoM8_wF9Ykm1ViFTjnKoMsgkCAABBXEByQ5OQfs3ubtTb2BGGdphB41H-DKDqqsLg35OkOlAIckSaI8foJ5iChCQFfY44FDPHWFp-jO0MIIhIaa4hO0JBP_k722fJL-0SYqavfZYs-z8hMwYgDVPHehcvl0oT0U0nEGFNckEiQtUhGtTCvi9ZUD0osLlyiWsWRkCFtdUmbiHJl9fr5MCpIMRspfBoBk3E7_-EPPTMzPkTU9BcSjKBcQ1AMdZBHEwTLER5QHaSYVxW842sg0Lf65PRbjMMd2NF24RN2EDrKhGvNSDqKO5OSe7Ip2V-d_0nYfHr3WZ9t0E_f15cX68ub73dy8XVT8vF_wRfLV6TzSUXAMP8HJfqm5E_ZraPuo-xzaRu3YT0ScXvTtMyMo1emNxYS54RpfgbLdy3GiIih44LTaN7O5h22T4joGdF543WJdf0nLcWnEHGuldF66VHbBjNacbH9hHjOjTomm9Tm8rb9LSwXC_Pf7N1JsCgs_eeP9t582lP1QO8IETJ9eQ4DbiKEB9NnAqQ1Nw8Wf-NsMgLyELBpZ4EU0Q3d_bnk8jw0mA-EjHN0ryXz84-BbPyLGnGV5V8Z54IWvJSDSXCkTAu00j5-o2G9nE4S2pFnPZQa4yz4e09xQ2TF90zGFIEYblK-Bs2OB2nmeExN-yDZ57h7I9hfb0xE8Z44zbEuMd0__1paNkMEmkPbU2rpIAha_yYNwXHvWnHq9PgDybDodhrQIwfFOc_5vypEm8GVFzsJJ_aLIowHyMgCKtR7h7CbawOJpEgBh3XsT-PcbwKwql4t0ZuWTpNKyIrTPN0ltriC6V7TyqyTWewzLF82KZb9gJ8uNb89sCydFaYNjtNawEvEuL-DeioL_8Ax7dT8g?type=png)](https://mermaid-js.github.io/mermaid-live-editor/edit#pako:eNq9WG1v2zYQ_iuCPgxu5wDtsE8GXMCbnTVAkhmJg22AAYKRKJuLRLIklcTr8t93pChZIqnEHYYZCEwf7453D--N-ZpmPCfpLM1KrNSS4p3E1ZYl8MmpJJmmnCWXNw3F8iQLIZKvDcF8vkeIMqoRmihSFu96G7JmfdrLljULhiuiBM5IssQa93U1BxjqJcc5kf098zkTmErl0XJgV0Sjxl4uD8P9oX3TJGCfJpl6RALr_TtPsgQjnBSt8I6ggpbEZ0KGC9n9gNdqRZowxWVMeSOGjFetLMvJcyjxclzG0AJ_Aqjusc72SNG_iL9RFwWRsR0DjXWHyLcxdIzTpKdv_uOHD0DoTp5_9L3OJMGaIHcJfsi8jEbKFWaAlFRhtFxB_JZuOwAh46ygO4-4-n29urm4Wl1vbtHy4sbb_fwH7K4XN4ur1WZ1c4vWi83n19CI3mtzrkOr-RGNsB0EIn7EtMT3EC3ZnmQPglOmVVS1kLwSGhVc9lijnEavvaQuyvs3pw-CjFwMZjm6r2mZo8rgqibD2_HB30gMULDdCP5-3LzHcqfg6_3Dk1kFNtRSEqYReRZE0sosNXwpjSsRddMZ3eMf-uvza2Nu45mzqKG0BQB-w2m9n0PNcJUd7JZhfs1ZgCSXwKVAMVimHT6RQPehXD3issam3v43YNoQIAWuSwC0023NbuNy6ExMQUEZLpHCj-QbBC1770hJFBihnLCncppUiiDDTAIXnA4yvLHhDXm2TBOr2dZVFbWufz1HI0cqUazgnkNhH7sia02TeeSZKnC6C8ggdrk4NJyaQ0qXUEsnitcyI02o5cZPWJ1m1J0i8oKJWo9Z9qUm8oAOAArjk6aQRIuR7fiTk2qyoM8_wF9Ykm1ViFTjnKoMsgkCAABBXEByQ5OQfs3ubtTb2BGGdphB41H-DKDqqsLg35OkOlAIckSaI8foJ5iChCQFfY44FDPHWFp-jO0MIIhIaa4hO0JBP_k722fJL-0SYqavfZYs-z8hMwYgDVPHehcvl0oT0U0nEGFNckEiQtUhGtTCvi9ZUD0osLlyiWsWRkCFtdUmbiHJl9fr5MCpIMRspfBoBk3E7_-EPPTMzPkTU9BcSjKBcQ1AMdZBHEwTLER5QHaSYVxW842sg0Lf65PRbjMMd2NF24RN2EDrKhGvNSDqKO5OSe7Ip2V-d_0nYfHr3WZ9t0E_f15cX68ub73dy8XVT8vF_wRfLV6TzSUXAMP8HJfqm5E_ZraPuo-xzaRu3YT0ScXvTtMyMo1emNxYS54RpfgbLdy3GiIih44LTaN7O5h22T4joGdF543WJdf0nLcWnEHGuldF66VHbBjNacbH9hHjOjTomm9Tm8rb9LSwXC_Pf7N1JsCgs_eeP9t582lP1QO8IETJ9eQ4DbiKEB9NnAqQ1Nw8Wf-NsMgLyELBpZ4EU0Q3d_bnk8jw0mA-EjHN0ryXz84-BbPyLGnGV5V8Z54IWvJSDSXCkTAu00j5-o2G9nE4S2pFnPZQa4yz4e09xQ2TF90zGFIEYblK-Bs2OB2nmeExN-yDZ57h7I9hfb0xE8Z44zbEuMd0__1paNkMEmkPbU2rpIAha_yYNwXHvWnHq9PgDybDodhrQIwfFOc_5vypEm8GVFzsJJ_aLIowHyMgCKtR7h7CbawOJpEgBh3XsT-PcbwKwql4t0ZuWTpNKyIrTPN0ltriC6V7TyqyTWewzLF82KZb9gJ8uNb89sCydFaYNjtNawEvEuL-DeioL_8Ax7dT8g)

## Post-processing 
[![](https://mermaid.ink/img/pako:eNp9kcFqwzAMhl_F6LQx7wVyHoXdCtnRYDRbbcVsOdjOoSt59zppaEsY0-lH-n7J_L6AS56gAxewlA_GY8ZoRK21dNU-lbrPyVEpu8-vvmc5BlKXBzbXexrrMFbrOW8GHivaeh5o02f5k3-zloWrtS-FwkGrO6bV44RW962vG7snSTli4F-yM7SumeU_LpfiNwtZd0IRCuXJtUWHWxQL8TSbbtIIaIjUXsC-5bqkZKCeKJKBrkmP-ceAkalxONbUn8VBd8BQSMM4tIu0_sPana6igoCi?type=png)](https://mermaid-js.github.io/mermaid-live-editor/edit#pako:eNp9kcFqwzAMhl_F6LQx7wVyHoXdCtnRYDRbbcVsOdjOoSt59zppaEsY0-lH-n7J_L6AS56gAxewlA_GY8ZoRK21dNU-lbrPyVEpu8-vvmc5BlKXBzbXexrrMFbrOW8GHivaeh5o02f5k3-zloWrtS-FwkGrO6bV44RW962vG7snSTli4F-yM7SumeU_LpfiNwtZd0IRCuXJtUWHWxQL8TSbbtIIaIjUXsC-5bqkZKCeKJKBrkmP-ceAkalxONbUn8VBd8BQSMM4tIu0_sPana6igoCi)


## System Overview
### I. Pre-processing Phase
This phase prepares the data for the pix2pix model. Detailed steps and scripts related to pre-processing can be found in preprocessing/README.md.

1. Data Augmentation:
    - Status: Feature in development (preprocessing/augmentation.py).
    - Details:
        - Flipping: Images are mirrored along their vertical axis.
        - Magnetic Field Adjustment: Images are multiplied by -1 to maintain magnetic field polarity.

2. Data Cube Creation:
    - Purpose: Generate a three-channel fits file.
        - Option 1: Use a single fits file. Script: preprocessing/data_cube/single_fits_pre.py.
        - Option 2: Use three separate fits files. Script: preprocessing/data_cube/three_fits_pre.py.
        **Note**: A corresponding post-processing script has not been developed.

3. Input and Target Fits Pairing:
    - Purpose: Generate a CSV file with fits file pairs using the Active Region ID (AR) and time step from the fits filename. Script: preprocessing/pair_files.py.

4. Dataset Splitting:
    - Purpose: Divide the dataset into training and testing subsets.
    - Implementation: The preprocessing/split_data.py script handles this, creating separate training and testing directories with associated pairs.csv files. The split ratio is user-defined.

### II. Main Application Phase
5. Model Training:
    - Purpose: Train the model using a version of pix2pix adapted for fits files.
    - Features:
        - Checkpoints: Save model states and sample images at intervals defined in config/hyperparameters.yaml.
        - Logging: Training data, logs, and hyperparameters are saved in a timestamped directory in the experiments folder.
    - Storage: Results are saved in the timestamped experiments directory.

6. Model Evaluation:
    - Purpose: Test the trained model using Mean Squared Error (MSE).
    - Outputs:
        - A CSV file with MSE values.
        - A comparison collage: input images at t1, target images at t2, predicted images at t2, and error images.
        - MSE visualizations: Box plots and histograms.
        -  A PDF report summarizing the evaluation results.
    - Storage: Results are saved in the evaluation sub-folder in the timestamped experiments directory.

### III. Post-processing Phase
7. Data Conversion:
   - Purpose: Convert the three-channel fits file back to individual fits files.
        - Option 1: Convert the predicted data cube to a single fits file by averaging channels and denormalizing based on input type. Script: postprocessing/single_fits_post.py.
        - Option 2: This feature, which will be the counterpart to preprocessing/data_cube/three_fits_pre.py script. 
        **Note**: This script is yet to be developed.

[![](https://mermaid.ink/img/pako:eNp9VNGOojAU_ZWmz-hIEVAeNgF0kn1w14w8LRhToCoJtE0p7jiO_76l6CzsONsEArfnnnPbc9sLzFhOoAf3JfudHbGQIFokNKFAjU3kv0Sxfm_vsbpJDwLzI_DjtSAjLlhG6rqgh2033w7fjBdYYuA3h4pQiWXBKBiBKFgMQGA0-gZ8dAkFwZIAnRI2Kbn2QKgFvf_kmkJlgI2SKgl4LmStXiV5VxgcvzQUcEH-VvOUK7Zdptieap2x26uMncKM-Xn7lQBqqzwK0uOvW4H0vwKyzfiSH3fLtOI1LgT4TnkjAaY5iLA4EKmFBvj0hu_FrC40jTe8LKTeqJrIWxah-SdvgniFCwp8rvCZ3v6-xFTTBWYciRa1Ug1Q9uaDzpgAxcsTLpvWmj7kkV4Yr1ktHzdDoHcYhOYlZPRERFd_z-PQ_NfjO1CyB3aH5s1updizY-CymhraMNRobX5uZCNU05ETKRlv27SlTuOQNVQSwduTwPbgk7eDPu7thSpLr3P5YxGrZ3uPpvdo70h1dpoJhQasiKhwkasTeGkRCZRHUpEEeuozVTYn0Ojie0ZlXbzdppzJhL8mMKFXxYEbyTZnmkFPioYYsOGqOcmiwMqdCnp7XNYf0WVeSCY-ghzTX4xV90z1C70LfIWeaVtjNDNtNHXsGZpYJjLgGXoj0x0jx0XudGY7tuNaM-tqwDdNMRnPkes4aG65E3c-c23bgETLrbo7Rl811z-AWl3J?type=png)](https://mermaid.live/edit#pako:eNp9VNGOojAU_ZWmz-hIEVAeNgF0kn1w14w8LRhToCoJtE0p7jiO_76l6CzsONsEArfnnnPbc9sLzFhOoAf3JfudHbGQIFokNKFAjU3kv0Sxfm_vsbpJDwLzI_DjtSAjLlhG6rqgh2033w7fjBdYYuA3h4pQiWXBKBiBKFgMQGA0-gZ8dAkFwZIAnRI2Kbn2QKgFvf_kmkJlgI2SKgl4LmStXiV5VxgcvzQUcEH-VvOUK7Zdptieap2x26uMncKM-Xn7lQBqqzwK0uOvW4H0vwKyzfiSH3fLtOI1LgT4TnkjAaY5iLA4EKmFBvj0hu_FrC40jTe8LKTeqJrIWxah-SdvgniFCwp8rvCZ3v6-xFTTBWYciRa1Ug1Q9uaDzpgAxcsTLpvWmj7kkV4Yr1ktHzdDoHcYhOYlZPRERFd_z-PQ_NfjO1CyB3aH5s1updizY-CymhraMNRobX5uZCNU05ETKRlv27SlTuOQNVQSwduTwPbgk7eDPu7thSpLr3P5YxGrZ3uPpvdo70h1dpoJhQasiKhwkasTeGkRCZRHUpEEeuozVTYn0Ojie0ZlXbzdppzJhL8mMKFXxYEbyTZnmkFPioYYsOGqOcmiwMqdCnp7XNYf0WVeSCY-ghzTX4xV90z1C70LfIWeaVtjNDNtNHXsGZpYJjLgGXoj0x0jx0XudGY7tuNaM-tqwDdNMRnPkes4aG65E3c-c23bgETLrbo7Rl811z-AWl3J)


## Docker 
**Visual Studio Code**:  While not mandatory, it is a versatile Integrated Development Environment (IDE) that offers a Docker extension, simplifying many Docker-related tasks.
- Download Visual Studio Code [here](https://code.visualstudio.com/download).
- Access its Docker extension [here](https://code.visualstudio.com/docs/containers/overview).

**Important Note**: When running the code inside a Docker container, please ensure that you use relative paths for any file or directory references. Absolute paths that work on your local machine might not be recognized correctly within the Docker container environment. Using relative paths will ensure consistent behavior and prevent potential file not found errors.

### Installation
#### Ubuntu and Debian-based Linux Distros
For a detailed installation guide, refer to the official Docker documentation [here](https://docs.docker.com/engine/install/ubuntu/). 

###### 1. Uninstall Old Docker Versions
Before you can install Docker Engine, you must first make sure that any conflicting packages are uninstalled.

- Run the following command to uninstall all conflicting packages:
    ```
    for pkg in docker.io docker-doc docker-compose podman-docker containerd runc; do sudo apt-get remove $pkg; done
    ```
###### 2. Install Docker Using the APT Repository
Before you install Docker Engine for the first time on a new host machine, you need to set up the Docker repository. Afterward, you can install and update Docker from the repository.

- Update the apt package index and install packages to allow apt to use a repository over HTTPS:
    ```
    sudo apt-get update
    sudo apt-get install ca-certificates curl gnupg
    ```
- Add Docker’s official GPG key:
    ```
    sudo install -m 0755 -d /etc/apt/keyrings
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
    sudo chmod a+r /etc/apt/keyrings/docker.gpg
    ```
- Use the following command to set up the repository:
    ```
    echo \
    "deb [arch="$(dpkg --print-architecture)" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
    "$(. /etc/os-release && echo "$VERSION_CODENAME")" stable" | \
    sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
    ```
**Note**: If you use an Ubuntu derivative distro, such as Linux Mint, you may need to use UBUNTU_CODENAME instead of VERSION_CODENAME.

- Update the apt package index:
    ```
    sudo apt-get update
    ```
###### 3. Install Docker Engine
- Now, install Docker Engine along with some additional packages:
    ```
    sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
    ```
- To verify the installation, run a test image:
    ```
    sudo docker run hello-world
    ```
    This command downloads a test image and runs it in a container. If you see a confirmation message, Docker Engine has been successfully installed.

###### 4. Addressing Permission Issues
If you encounter errors when trying to run Docker without sudo, it's due to the Docker user group not having any users. To resolve this:
- Add your user to the Docker group:
  ```
  sudo usermod -aG docker $USER
  ```
- Either log out and log back in to apply the changes or use the following command for immediate application:
  ```
  newgrp docker
  ```
- Verify that you can run docker commands without sudo:
  ```
  docker run hello-world
  ```
---
  
#### Windows
For a detailed installation guide, refer to the official Docker documentation [here](https://docs.docker.com/desktop/install/windows-install/).

---

#### macOS
For a detailed installation guide, refer to the official Docker documentation [here](https://docs.docker.com/desktop/install/mac-install/).

---

### Setup
#### CPU-Only Environments on Linux, Windows, and macOS
##### 1. Create a Docker Image from the Dockerfile
**Note**: Uncomment "FROM tensorflow/tensorflow:2.13.0" in the Dockerfile, and comment out "FROM tensorflow/tensorflow:2.13.0-gpu".
- Navigate to the directory containing the Dockerfile:
    ```
    cd /path/to/dockerfile
    ```
- Build the Docker image:
    ```
    docker build -t pix2pix-cpu-image .
    ```
    This command builds a Docker image named pix2pix-cpu-image from the Dockerfile in the current directory.
##### 2. Build Docker Container from the Image
To build a Docker container from the image:
- **Linux**:
    ```
    docker run -it --net=host --name pix2pix-cpu-container -v $(pwd):/app pix2pix-cpu-image bash
    ```
- **Windows and macOS**:
    ```
    docker run -it --name pix2pix-cpu-container -v $(pwd):/app pix2pix-cpu-image bash
    ```
This command creates a Docker container named pix2pix-cpu-container from the pix2pix-cpu-image image and runs it in interactive mode. It also mounts the current directory to the /app directory in the container.

---

#### GPU-Accelerated Environments on Ubuntu and Debian-based Linux Distros
**Important**: Ensure your system is equipped with an NVIDIA GPU that supports CUDA. If not, you'll need to follow the CPU version of this guide.

##### Prerequisites
- **NVIDIA Drivers**: Before you get started, make sure you have installed the NVIDIA driver for your Linux distribution. The recommended way to install drivers is to use the package manager for your distribution but other installer mechanisms are also available (e.g. by downloading .run installers from NVIDIA Driver Downloads).

###### 1. NVIDIA Container Toolkit Installation
For a detailed walkthrough, refer to the official NVIDIA guide [here](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#nvidia-drivers).

###### 1.1. Install NVIDIA Container Toolkit
- To generate Container Device Interface (CDI) specifications for NVIDIA devices on your system, you need the base components of the NVIDIA Container Toolkit.
    ```
    sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit-base
    ```
- To confirm the installation of the NVIDIA Container Toolkit CLI (nvidia-ctk), run:
    ```
    nvidia-ctk --version
    ```
###### 1.2. Generate a CDI Specification
- To generate a CDI specification that references all devices:
    ```
    sudo nvidia-ctk cdi generate --output=/etc/cdi/nvidia.yaml
    ```
- To view the names of the generated devices:
  ```
  grep "  name:" /etc/cdi/nvidia.yaml
  ```
###### 1.3. Setting up NVIDIA Container Toolkit
- Set up the package repository and GPG key:
    ```
    distribution=$(. /etc/os-release;echo $ID$VERSION_ID) \
    && curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg \
    && curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
        sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
        sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
    ```
- Update the package listing and install the nvidia-container-toolkit:
    ```
    sudo apt-get update
    sudo apt-get install -y nvidia-container-toolkit
    ```
- Configure the Docker daemon to recognize the NVIDIA Container Runtime:
    ```
    sudo nvidia-ctk runtime configure --runtime=docker
    ```
- Restart the Docker daemon:
    ```
    sudo systemctl restart docker
    ```
- Test the setup by running a base CUDA container:
    ```
    sudo docker run --rm --runtime=nvidia --gpus all nvidia/cuda:11.6.2-base-ubuntu20.04 nvidia-smi
    ```

###### 2. Pull TensorFlow GPU Docker Image
- To pull the 2.13.0 TensorFlow GPU image:
    ```
    docker pull tensorflow/tensorflow:2.13.0-gpu
    ```

###### 3. Pull CUDA Docker Image
- To pull the 12.2.0 CUDA image:
    ```
    docker pull nvidia/cuda:12.2.0-devel-ubuntu20.04
    ```
- To verify the GPU:
    ```
    lspci | grep -i nvidia
    ```
- To confirm the installation of nvidia-docker and CUDA:
    ```
    sudo docker run --gpus all --rm nvidia/cuda:12.2.0-devel-ubuntu20.04 nvidia-smi
    ```

##### 5. Build Docker Container
**Note**: Uncomment "FROM tensorflow/tensorflow:2.13.0-gpu" in the Dockerfile, and comment out "FROM tensorflow/tensorflow:2.13.0".
###### 5.1. Create a Docker Image from the Dockerfile
- Navigate to the directory containing the Dockerfile:
    ```
    cd /path/to/dockerfile
    ```
- Build the Docker image:
    ```
    docker build -t pix2pix-gpu-image .
    ```
    This command builds a Docker image named pix2pix-gpu-image from the Dockerfile in the current directory.
###### 5.2. Build Docker Container from the Image
- To build a Docker container from the image:
    ```
    docker run -it --net=host --gpus=all --name pix2pix-gpu-container -v $(pwd):/app pix2pix-gpu-image bash
    ```
    This command creates a Docker container named pix2pix-gpu-container from the pix2pix-gpu-image image and runs it in interactive mode with the host network and all GPUs enabled. It also mounts the current directory to the /app directory in the container.

##### GPU Monitoring
Monitoring your GPU is important for many machine learning applications:
- **Thermal Management**: ML tasks can be computationally intensive and lead to increased GPU temperatures. Monitoring helps in preventing overheating, which can disrupt long training sessions. Different GPU models, like the A100 and the 2080, have varying optimal operating temperatures. It's essential to be aware of the recommended temperature range for your specific GPU model. To determine the safe operating temperature for your GPU:
    1. Google the official specifications of your GPU model. For instance, search for "NVIDIA A100 safe operating temperature" or "RTX 2080 recommended temperature range."
    2. Refer to the manufacturer's documentation or official website for precise details.
    3. As a general rule of thumb, it's always better to operate at temperatures below the maximum threshold. 
- **Resource Management**: Deep learning models, in particular, can consume significant GPU memory. Keeping an eye on memory usage ensures that you're not exceeding available resources, which can lead to training failures or reduced model performance.

To monitor GPU metrics such as temperature, utilization, and memory usage:
``` 
nvidia-smi
```
To monitor GPU metrics in real-time you can download tool such as nvtop
  
To install nvtop:
```
sudo apt install nvtop
```
To run nvtop:
```
nvtop
``` 

---

### Docker Management
You can manage Docker containers and images either through your IDE or the terminal:
- List currently running Docker containers:
    ```
    docker ps
    ```
- List all Docker containers, including stopped ones:
    ```
    docker ps -a
    ```
- To stop a running container:
    ```
    docker stop [CONTAINER_NAME/ID]
    ```
- To remove a container:
    ```
    docker rm [CONTAINER_NAME/ID]
    ```
- List all Docker images:
    ```
    docker images
    ```
- Remove a Docker image:
    ```
    docker rmi [IMAGE_NAME/ID]
    ```
